{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlqlD_I3InEZ",
        "outputId": "bfba54f1-8a4e-4245-ea61-893591bb2c2f"
      },
      "outputs": [],
      "source": [
        "# !pip install spotipy\n",
        "# !pip install requestes\n",
        "# !pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scl5f4eaWOGx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAuu-oJVZ4P_",
        "outputId": "926ce726-94e1-4d07-8fee-2cecc33ceb34"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "client_id = \"your_client_id\"\n",
        "client_secret = \"your_client_secret\"\n",
        "\n",
        "auth_url = 'https://accounts.spotify.com/api/token'\n",
        "auth_response = requests.post(auth_url, {\n",
        "    'grant_type': 'client_credentials',\n",
        "    'client_id': os.environ.get(\"SPOTIFY_CLIENT_ID\"),\n",
        "    'client_secret': os.environ.get(\"SPOTIFY_CLIENT_SECRET\"),\n",
        "})\n",
        "\n",
        "auth_data = auth_response.json()\n",
        "token = auth_data['access_token']\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "test_url = \"https://api.spotify.com/v1/search?q=track:a&type=track&limit=1\"\n",
        "\n",
        "response = requests.get(test_url, headers=headers)\n",
        "print(f\"Status: {response.status_code}\")\n",
        "print(f\"Response: {response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA22XG6TWPwy",
        "outputId": "fcf33796-09bc-4336-e650-373b38c74b9d"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"spotify_scraper.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger()\n",
        "\n",
        "class SpotifyScraper:\n",
        "    def __init__(self, client_id, client_secret):\n",
        "        self.client_id = client_id\n",
        "        self.client_secret = client_secret\n",
        "        self.token = None\n",
        "        self.token_expiry = 0\n",
        "        self.base_url = \"https://api.spotify.com/v1\"\n",
        "        self.csv_file = \"spotify_songs.csv\"\n",
        "        self.checkpoint_file = \"checkpoint.json\"\n",
        "        self.batch_size = 50  # Number of songs to write at once\n",
        "        self.current_batch = []\n",
        "        self.total_songs_collected = 0\n",
        "        self.max_retries = 5\n",
        "        self.retry_delay = 10  # seconds\n",
        "\n",
        "        # Fields we want to collect\n",
        "        self.fields = [\n",
        "            'track_name', 'track_id', 'artists', 'artist_ids', 'album_name', 'album_id',\n",
        "            'popularity', 'duration_ms', 'explicit',\n",
        "            'danceability', 'energy', 'release_date', 'track_number_in_album',\n",
        "            'total_tracks_in_album', 'album_type', 'genres'\n",
        "        ]\n",
        "\n",
        "        # Create/load CSV file with headers\n",
        "        self._setup_csv()\n",
        "\n",
        "        # Load checkpoint if exists\n",
        "        self.checkpoint = self._load_checkpoint()\n",
        "\n",
        "    def _get_token(self):\n",
        "        \"\"\"Get or refresh the Spotify API token\"\"\"\n",
        "        current_time = time.time()\n",
        "\n",
        "        # If token exists and is still valid, return it\n",
        "        if self.token and current_time < self.token_expiry:\n",
        "            return self.token\n",
        "\n",
        "        logger.info(\"Getting new access token\")\n",
        "        auth_url = 'https://accounts.spotify.com/api/token'\n",
        "        auth_response = requests.post(auth_url, {\n",
        "            'grant_type': 'client_credentials',\n",
        "            'client_id': self.client_id,\n",
        "            'client_secret': self.client_secret,\n",
        "        })\n",
        "\n",
        "        if auth_response.status_code != 200:\n",
        "            logger.error(f\"Failed to get token: {auth_response.text}\")\n",
        "            raise Exception(\"Authentication failed\")\n",
        "\n",
        "        auth_data = auth_response.json()\n",
        "        self.token = auth_data['access_token']\n",
        "        self.token_expiry = current_time + auth_data['expires_in'] - 60  # Buffer of 60 seconds\n",
        "        return self.token\n",
        "\n",
        "    def _setup_csv(self):\n",
        "        \"\"\"Set up the CSV file with headers if it doesn't exist\"\"\"\n",
        "        if not os.path.exists(self.csv_file) or os.path.getsize(self.csv_file) == 0:\n",
        "            with open(self.csv_file, 'w', newline='', encoding='utf-8') as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=self.fields)\n",
        "                writer.writeheader()\n",
        "            logger.info(f\"Created new CSV file: {self.csv_file}\")\n",
        "\n",
        "    def _load_checkpoint(self):\n",
        "        \"\"\"Load the checkpoint file if it exists\"\"\"\n",
        "        if os.path.exists(self.checkpoint_file):\n",
        "            with open(self.checkpoint_file, 'r') as f:\n",
        "                checkpoint = json.load(f)\n",
        "\n",
        "            logger.info(f\"Loaded checkpoint: {checkpoint}\")\n",
        "\n",
        "            # Count existing songs in CSV to set total_songs_collected\n",
        "            if os.path.exists(self.csv_file):\n",
        "                with open(self.csv_file, 'r', encoding='utf-8') as f:\n",
        "                    self.total_songs_collected = sum(1 for line in f) - 1  # Subtract 1 for header\n",
        "                logger.info(f\"Found {self.total_songs_collected} existing songs in CSV\")\n",
        "\n",
        "            return checkpoint\n",
        "\n",
        "        # Default checkpoint\n",
        "        return {\n",
        "            \"offset\": 0,\n",
        "            \"market\": \"US\",\n",
        "            \"last_letter\": \"a\",\n",
        "            \"current_letter_index\": 0,\n",
        "            \"search_query\": \"a\",\n",
        "            \"last_query_offset\": 0\n",
        "        }\n",
        "\n",
        "    def _save_checkpoint(self):\n",
        "        \"\"\"Save the current state to checkpoint file\"\"\"\n",
        "        with open(self.checkpoint_file, 'w') as f:\n",
        "            json.dump(self.checkpoint, f)\n",
        "        logger.info(f\"Saved checkpoint: {self.checkpoint}\")\n",
        "\n",
        "    def _write_batch_to_csv(self):\n",
        "        \"\"\"Write the current batch of songs to CSV\"\"\"\n",
        "        if not self.current_batch:\n",
        "            return\n",
        "\n",
        "        with open(self.csv_file, 'a', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=self.fields)\n",
        "            writer.writerows(self.current_batch)\n",
        "\n",
        "        logger.info(f\"Wrote {len(self.current_batch)} songs to CSV\")\n",
        "        self.current_batch = []\n",
        "\n",
        "    def _make_api_request(self, endpoint, params=None):\n",
        "        \"\"\"Make a request to the Spotify API with retry logic\"\"\"\n",
        "        token = self._get_token()\n",
        "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "        url = f\"{self.base_url}/{endpoint}\"\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "                # Handle rate limiting\n",
        "                if response.status_code == 429:\n",
        "                    retry_after = int(response.headers.get('Retry-After', self.retry_delay))\n",
        "                    logger.warning(f\"Rate limited. Waiting for {retry_after} seconds\")\n",
        "                    time.sleep(retry_after)\n",
        "                    continue\n",
        "\n",
        "                # Handle expired token\n",
        "                if response.status_code == 401:\n",
        "                    # Force token refresh\n",
        "                    self.token_expiry = 0\n",
        "                    token = self._get_token()\n",
        "                    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "                    continue\n",
        "\n",
        "                # Handle other errors\n",
        "                if response.status_code != 200:\n",
        "                    logger.error(f\"API error: {response.status_code} - Full response: {response.text}\")\n",
        "                    logger.error(f\"Request URL: {url}\")\n",
        "                    logger.error(f\"Request params: {params}\")\n",
        "                    time.sleep(self.retry_delay)\n",
        "                    continue\n",
        "\n",
        "                return response.json()\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Request failed (attempt {attempt+1}/{self.max_retries}): {str(e)}\")\n",
        "                if attempt < self.max_retries - 1:\n",
        "                    time.sleep(self.retry_delay)\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "    def _get_audio_features(self, track_ids):\n",
        "        \"\"\"Get audio features for multiple tracks\"\"\"\n",
        "        if not track_ids:\n",
        "            return {}\n",
        "\n",
        "        chunks = [track_ids[i:i+50] for i in range(0, len(track_ids), 20)]\n",
        "        all_features = {}\n",
        "\n",
        "        for chunk in chunks:\n",
        "            try:\n",
        "                ids_param = \",\".join(chunk)\n",
        "                features_response = self._make_api_request(f\"audio-features?ids={ids_param}\")\n",
        "\n",
        "                if features_response and 'audio_features' in features_response:\n",
        "                    for item in features_response['audio_features']:\n",
        "                        if item:  # Sometimes we get None values\n",
        "                            all_features[item['id']] = item\n",
        "\n",
        "                # Delay between requests\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error getting audio features for chunk: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return all_features\n",
        "\n",
        "    def _get_artist_genres(self, artist_ids):\n",
        "        \"\"\"Get genres for multiple artists\"\"\"\n",
        "        if not artist_ids:\n",
        "            return {}\n",
        "\n",
        "        # Spotify allows up to 50 IDs per request\n",
        "        chunks = [artist_ids[i:i+50] for i in range(0, len(artist_ids), 50)]\n",
        "        artist_genres = {}\n",
        "\n",
        "        for chunk in chunks:\n",
        "            ids_param = \",\".join(chunk)\n",
        "            artists_response = self._make_api_request(f\"artists?ids={ids_param}\")\n",
        "\n",
        "            if not artists_response or 'artists' not in artists_response:\n",
        "                continue\n",
        "\n",
        "            for artist in artists_response['artists']:\n",
        "                if artist:\n",
        "                    artist_genres[artist['id']] = artist.get('genres', [])\n",
        "\n",
        "            # Be nice to the API\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        return artist_genres\n",
        "\n",
        "    def _process_track(self, track, audio_features, artist_genres):\n",
        "        \"\"\"Process a track and convert it to our CSV format\"\"\"\n",
        "        # Basic track info\n",
        "        track_data = {\n",
        "            'track_id': track['id'],\n",
        "            'track_name': track['name'],\n",
        "            'popularity': track['popularity'],\n",
        "            'duration_ms': track['duration_ms'],\n",
        "            'explicit': int(track['explicit']),\n",
        "            'track_number_in_album': track['track_number'],\n",
        "            'album_name': track['album']['name'],\n",
        "            'album_id': track['album']['id'],\n",
        "            'total_tracks_in_album': track['album'].get('total_tracks', 0),\n",
        "            'album_type': track['album']['album_type'],\n",
        "            'release_date': track['album'].get('release_date', ''),\n",
        "        }\n",
        "\n",
        "        # Process artists\n",
        "        artists = track['artists']\n",
        "        artist_names = [artist['name'] for artist in artists]\n",
        "        artist_ids_list = [artist['id'] for artist in artists]\n",
        "\n",
        "        track_data['artists'] = \", \".join(artist_names)\n",
        "        track_data['artist_ids'] = \", \".join(artist_ids_list)\n",
        "\n",
        "        # Add audio features\n",
        "        if track['id'] in audio_features:\n",
        "            features = audio_features[track['id']]\n",
        "            track_data['danceability'] = features.get('danceability', 0)\n",
        "            track_data['energy'] = features.get('energy', 0)\n",
        "        else:\n",
        "            track_data['danceability'] = 0\n",
        "            track_data['energy'] = 0\n",
        "\n",
        "        # Add genres\n",
        "        genres_set = set()\n",
        "        for artist_id in artist_ids_list:\n",
        "            if artist_id in artist_genres:\n",
        "                genres_set.update(artist_genres[artist_id])\n",
        "\n",
        "        track_data['genres'] = \", \".join(genres_set)\n",
        "\n",
        "        return track_data\n",
        "\n",
        "    def _search_tracks(self, query, offset=0, limit=50):\n",
        "        \"\"\"Search for tracks with a specific query\"\"\"\n",
        "        search_params = {\n",
        "            'q': query,\n",
        "            'type': 'track',\n",
        "            'limit': limit,\n",
        "            'offset': offset,\n",
        "            'market': self.checkpoint['market']\n",
        "        }\n",
        "\n",
        "        return self._make_api_request('search', search_params)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the scraper with checkpoint recovery\"\"\"\n",
        "        logger.info(\"Starting Spotify song scraper\")\n",
        "\n",
        "        # Define search strategy\n",
        "        search_chars = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
        "        year_range = range(1900, datetime.now().year + 1)\n",
        "\n",
        "        try:\n",
        "            # Resume from checkpoint\n",
        "            current_letter_index = self.checkpoint['current_letter_index']\n",
        "            search_query = self.checkpoint['search_query']\n",
        "            offset = self.checkpoint['last_query_offset']\n",
        "            \n",
        "            # Progress logging\n",
        "            logger.info(f\"Resuming with query '{search_query}' at offset {offset}\")\n",
        "\n",
        "            # Iterating through search combinations\n",
        "            while current_letter_index < len(search_chars):\n",
        "                current_letter = search_chars[current_letter_index]\n",
        "\n",
        "                # Use different search strategies\n",
        "                search_strategies = [\n",
        "                    f\"track:{current_letter}\"\n",
        "                ] + [f\"year:{year}\" for year in year_range]\n",
        "\n",
        "                # Find where we left off in search strategies\n",
        "                strategy_index = search_strategies.index(search_query) if search_query in search_strategies else 0\n",
        "                search_strategies = search_strategies[strategy_index:]\n",
        "\n",
        "                for strategy in search_strategies:\n",
        "                    search_query = strategy\n",
        "                    # Only reset offset if we're starting a new strategy\n",
        "                    if strategy != self.checkpoint['search_query']:\n",
        "                        offset = 0\n",
        "\n",
        "                    while True:\n",
        "                        logger.info(f\"Searching with query '{search_query}' at offset {offset}\")\n",
        "\n",
        "                        # Update checkpoint before making the request\n",
        "                        self.checkpoint.update({\n",
        "                            'search_query': search_query,\n",
        "                            'last_query_offset': offset,\n",
        "                            'current_letter_index': current_letter_index\n",
        "                        })\n",
        "                        self._save_checkpoint()\n",
        "                        \n",
        "                        # Rest of the code remains the same...\n",
        "\n",
        "                        # Search for tracks\n",
        "                        search_results = self._search_tracks(search_query, offset=offset)\n",
        "\n",
        "                        if not search_results or 'tracks' not in search_results or not search_results['tracks']['items']:\n",
        "                            # No more results for this query\n",
        "                            break\n",
        "\n",
        "                        tracks = search_results['tracks']['items']\n",
        "\n",
        "                        # Get audio features for all tracks in batch\n",
        "                        track_ids = [track['id'] for track in tracks]\n",
        "                        audio_features = self._get_audio_features(track_ids)\n",
        "\n",
        "                        # Get artist genres\n",
        "                        all_artist_ids = []\n",
        "                        for track in tracks:\n",
        "                            for artist in track['artists']:\n",
        "                                all_artist_ids.append(artist['id'])\n",
        "\n",
        "                        artist_genres = self._get_artist_genres(all_artist_ids)\n",
        "\n",
        "                        # Process tracks\n",
        "                        for track in tracks:\n",
        "                            # Skip if we already have this track (check by ID)\n",
        "                            if any(item['track_id'] == track['id'] for item in self.current_batch):\n",
        "                                continue\n",
        "\n",
        "                            # Process track and add to batch\n",
        "                            track_data = self._process_track(track, audio_features, artist_genres)\n",
        "                            self.current_batch.append(track_data)\n",
        "\n",
        "                            # Write to CSV if we've reached batch size\n",
        "                            if len(self.current_batch) >= self.batch_size:\n",
        "                                self._write_batch_to_csv()\n",
        "                                self.total_songs_collected += len(self.current_batch)\n",
        "\n",
        "                        logger.info(f\"Total songs collected: {self.total_songs_collected}\")\n",
        "\n",
        "                        # Check if there are more tracks\n",
        "                        if len(tracks) < 50 or offset + 50 >= search_results['tracks']['total']:\n",
        "                            break\n",
        "\n",
        "                        # Move to next page\n",
        "                        offset += 50\n",
        "                        time.sleep(1)  # Be nice to the API\n",
        "\n",
        "                # Move to next letter\n",
        "                current_letter_index += 1\n",
        "                self.checkpoint['current_letter_index'] = current_letter_index\n",
        "                self._save_checkpoint()\n",
        "\n",
        "            # Write any remaining tracks\n",
        "            self._write_batch_to_csv()\n",
        "            logger.info(f\"Completed scraping. Total songs collected: {self.total_songs_collected}\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logger.info(\"Process interrupted by user\")\n",
        "            self._write_batch_to_csv()\n",
        "            self._save_checkpoint()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error occurred: {str(e)}\")\n",
        "            self._write_batch_to_csv()\n",
        "            self._save_checkpoint()\n",
        "            raise\n",
        "\n",
        "# If running as a script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load credentials from environment variables\n",
        "    load_dotenv()\n",
        "    \n",
        "    client_id = os.environ.get(\"SPOTIFY_CLIENT_ID\")\n",
        "    client_secret = os.environ.get(\"SPOTIFY_CLIENT_SECRET\")\n",
        "\n",
        "    if not client_id or not client_secret:\n",
        "        print(\"Please set SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET environment variables\")\n",
        "        exit(1)\n",
        "\n",
        "    scraper = SpotifyScraper(client_id, client_secret)\n",
        "    scraper.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
